{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "from scipy.spatial import distance\n",
    "from keras.models import load_model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set directory and path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lab513/face_128-dim/images\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIR = os.getcwd() #main directory\n",
    "\n",
    "IMG_DIR = os.path.join(ROOT_DIR, 'images') #images directory\n",
    "\n",
    "print(IMG_DIR)\n",
    "\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, 'model') #model directory\n",
    "\n",
    "CASCADE_PATH = os.path.join(MODEL_DIR, 'cv2', 'haarcascade_frontalface_alt2.xml') #cascade path\n",
    "\n",
    "KERAS_PATH = os.path.join(MODEL_DIR ,'keras', 'facenet_keras.h5') #keras path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(KERAS_PATH) #load keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = os.listdir(IMG_DIR) #read the images people names\n",
    "image_size = 160 #set image size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image whitening process, removes redundant information in the image, also highlights the features, and defines L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prewhiten(x):\n",
    "    if x.ndim == 4:\n",
    "        axis = (1, 2, 3)\n",
    "        size = x[0].size\n",
    "    elif x.ndim == 3:\n",
    "        axis = (0, 1, 2)\n",
    "        size = x.size\n",
    "    else:\n",
    "        raise ValueError('Dimension should be 3 or 4')\n",
    "\n",
    "    mean = np.mean(x, axis=axis, keepdims=True)\n",
    "    std = np.std(x, axis=axis, keepdims=True)\n",
    "    std_adj = np.maximum(std, 1.0/np.sqrt(size))\n",
    "    y = (x - mean) / std_adj\n",
    "    return y\n",
    "\n",
    "def l2_normalize(x, axis=-1, epsilon=1e-10):\n",
    "    output = x / np.sqrt(np.maximum(np.sum(np.square(x), axis=axis, keepdims=True), epsilon))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_align_images(filepaths, margin):\n",
    "    cascade = cv2.CascadeClassifier(CASCADE_PATH)\n",
    "    \n",
    "    aligned_images = []\n",
    "    for filepath in filepaths:\n",
    "        img = imread(filepath)\n",
    "\n",
    "        faces = cascade.detectMultiScale(img,\n",
    "                                         scaleFactor=1.1,\n",
    "                                         minNeighbors=3)\n",
    "        (x, y, w, h) = faces[0]\n",
    "        cropped = img[y-margin//2:y+h+margin//2,\n",
    "                      x-margin//2:x+w+margin//2, :]\n",
    "        aligned = resize(cropped, (image_size, image_size), mode='reflect')\n",
    "        aligned_images.append(aligned)\n",
    "            \n",
    "    return np.array(aligned_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate embedding values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_embs(filepaths, margin=10, batch_size=1):   ### !!!! 這裡要修改\n",
    "    aligned_images = prewhiten(load_and_align_images(filepaths, margin))\n",
    "    pd = []\n",
    "    for start in range(0, len(aligned_images), batch_size):\n",
    "        pd.append(model.predict_on_batch(aligned_images[start:start+batch_size]))\n",
    "    embs = l2_normalize(np.concatenate(pd))\n",
    "\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test embedding values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.11268118e-01,  5.62553816e-02, -4.35333215e-02,\n",
       "         8.02948475e-02, -5.32137183e-03,  3.16822305e-02,\n",
       "        -1.55051723e-01, -8.39145854e-03,  1.23464011e-01,\n",
       "        -1.57863021e-01, -9.87251842e-05,  2.95289960e-02,\n",
       "        -1.21730231e-02,  1.33604124e-01,  4.42545824e-02,\n",
       "         9.26484987e-02,  2.25569420e-02,  7.34831467e-02,\n",
       "         3.35663441e-03,  1.88413829e-01,  1.17630959e-02,\n",
       "        -3.61146801e-03,  5.50837889e-02,  8.04516971e-02,\n",
       "        -1.36016896e-02,  1.52466837e-02, -1.02662660e-01,\n",
       "         1.70878470e-02,  1.41111389e-01,  3.25863669e-03,\n",
       "        -3.41998450e-02,  1.94938276e-02, -1.12565354e-01,\n",
       "         1.29556522e-01, -6.93163946e-02,  4.67346273e-02,\n",
       "         9.33347642e-03,  3.98831852e-02,  8.75391215e-02,\n",
       "        -6.98434841e-03,  2.20776513e-01, -1.06723413e-01,\n",
       "        -4.00678068e-02, -3.19848210e-02, -4.43502292e-02,\n",
       "         3.93333286e-03,  5.86186908e-02, -2.44966611e-01,\n",
       "         2.72554737e-02,  1.91387143e-02, -3.30376327e-02,\n",
       "         7.58101419e-02,  4.85481322e-02, -5.09747006e-02,\n",
       "        -6.65946230e-02, -2.96634971e-03,  5.55873476e-02,\n",
       "         2.05684304e-02,  1.19922526e-01,  4.96450327e-02,\n",
       "         6.48477115e-03,  5.51848970e-02, -9.12373047e-03,\n",
       "         9.27010924e-03,  5.13267517e-03, -6.20174129e-03,\n",
       "         2.73693174e-01, -3.53190266e-02,  2.54875086e-02,\n",
       "        -1.02652581e-02, -2.62191403e-03, -2.03531962e-02,\n",
       "         4.60877307e-02,  8.63439888e-02, -5.87432571e-02,\n",
       "         1.39639443e-02,  1.88696720e-02, -7.83746615e-02,\n",
       "        -1.02699965e-01, -1.21377908e-01,  6.32297248e-02,\n",
       "        -7.71145150e-02,  1.19000643e-01,  2.20068712e-02,\n",
       "        -5.55358678e-02,  6.01619929e-02, -2.63607223e-02,\n",
       "         1.24283716e-01, -1.51694208e-01, -5.65223023e-02,\n",
       "         1.34015575e-01, -1.33900061e-01, -7.72512183e-02,\n",
       "        -1.38325959e-01, -1.06026389e-01, -6.07838035e-02,\n",
       "         4.57541309e-02, -3.19545791e-02, -1.83274783e-02,\n",
       "         3.31864879e-02, -2.36185327e-01,  1.02660157e-01,\n",
       "        -9.92450640e-02,  5.51278479e-02,  3.25939469e-02,\n",
       "         4.42945696e-02,  1.08123407e-01,  2.29155719e-02,\n",
       "        -3.84438224e-02,  9.31441262e-02, -4.50941958e-02,\n",
       "         1.81438863e-01,  1.03037700e-01, -1.07850313e-01,\n",
       "         3.81227694e-02, -1.80710182e-01,  4.65341806e-02,\n",
       "        -4.62655500e-02,  1.85272861e-02, -1.10843755e-01,\n",
       "         2.44873390e-02,  3.82800028e-02,  1.81889504e-01,\n",
       "        -1.31654128e-01,  7.68266395e-02, -1.28084511e-01,\n",
       "         9.52720419e-02,  9.67951417e-02]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_embs(['/home/lab513/face_128-dim/images/BillGates/Bill_Gates_0000.jpg'])  ###!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define to calculate Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dist1(imgemb0,imgemb1):\n",
    "    emb0 = [imgemb0]\n",
    "    emb1 = [imgemb1]\n",
    "    return distance.euclidean(calc_embs(emb0), calc_embs(emb1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the calculation and sort the pictures of each directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_dist(image_dirpath): #output a list of img distances in img_path\n",
    "    img_path = os.listdir(image_dirpath)    #讀出image_dirpath下的資料夾\n",
    "    for i in range(len(img_path)):\n",
    "        name_paths = os.path.join(image_dirpath,str(img_path[i]))  #用迴圈依序讀出各資料夾並拼接出絕對路徑\n",
    "        sort_list = []                                             #/home/user/Downloads/keras-facenet/data/images/ + BillGates\n",
    "        name_imgpaths = [os.path.join(name_paths, f) for f in os.listdir(name_paths)]#因為listdir只能讀路徑無法讀列表 所以必須把name_paths組合成絕對路徑\n",
    "                                                                    #讀取目錄下的圖片再為他們拼接成絕對路徑#'/home/user/Downloads/keras-facenet/data/images/BillGates/ + Bill_Gates_0002 (copy).jpg'\n",
    "        embs = calc_embs(name_imgpaths)\n",
    "        n =len(name_imgpaths)\n",
    "        print(n)\n",
    "        for j in range(n-1):\n",
    "            for k in range(n-j-1):\n",
    "                #print(j,j+k+1)\n",
    "                result = calc_dist1(name_imgpaths[j], name_imgpaths[j+k+1])\n",
    "                sort_list.append(result)\n",
    "        print(sorted(sort_list, key=float))\n",
    "    return sorted(sort_list, key=float),embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[0.5930255055427551, 0.618617832660675, 0.7355362176895142]\n",
      "3\n",
      "[1.1636340618133545, 1.3112479448318481, 1.4303568601608276]\n",
      "3\n",
      "[0.4924164414405823, 0.5091053247451782, 0.569210410118103]\n",
      "3\n",
      "[0.5079659819602966, 0.6593101620674133, 0.7331599593162537]\n"
     ]
    }
   ],
   "source": [
    "(ll, emb) = img_dist(IMG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
